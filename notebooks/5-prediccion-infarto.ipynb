{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Enfermedades del Corazón\n",
    "\n",
    "En este ejemplo, trabajaremos con el famoso conjunto de datos \"UCI Heart Disease\". Este conjunto de datos contiene un conjunto de atributos relacionados con pacientes potencialmente afectados por una enfermedad cardiovascular (ECV). Las ECV son una de las principales causas de mortalidad, pero se estima que hasta un 90% de las ECV podrían ser prevenibles. Un diagnóstico temprano podría ser esencial en la mayoría de los casos y la inteligencia artificial puede lograr este objetivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación Binaria en Aprendizaje Automático\n",
    "\n",
    "### Entrenamiento de un Clasificador Binario\n",
    "1. **Preparación de Datos**: Divide el conjunto de datos en entrenamiento y prueba.\n",
    "2. **Selección del Modelo**: Elige un modelo de clasificación binaria (ej. regresión logística).\n",
    "3. **Entrenamiento del Modelo**: Entrena el modelo usando una biblioteca como sklearn.\n",
    "4. **Ajuste de Hiperparámetros**: Mejora el rendimiento ajustando los hiperparámetros.\n",
    "\n",
    "### Evaluación del Clasificador Binario\n",
    "1. **Matriz de Confusión**: Muestra predicciones correctas e incorrectas divididas en dos clases.\n",
    "2. **Precisión (Precision)**: Proporción de identificaciones positivas correctas.\n",
    "   - `Precisión = VP / (VP + FP)`\n",
    "3. **Recall (Sensibilidad)**: Proporción de positivos reales identificados correctamente.\n",
    "   - `Recall = VP / (VP + FN)`\n",
    "4. **Puntuación F1 (F1 Score)**: Promedio ponderado de precisión y recall.\n",
    "   - `F1 = 2 * (Precisión * Recall) / (Precisión + Recall)`\n",
    "5. **Curva ROC y AUC**: Rendimiento del clasificador y medida agregada de rendimiento.\n",
    "6. **Validación Cruzada**: Evalúa la robustez del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leemos los datos\n",
    "data = pd.read_csv('../data/raw/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le damos una vueltecilla a ver que pintan tienen...\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **age**: edad en años.\n",
    "2. **sex**: sexo (1 = masculino; 0 = femenino).\n",
    "3. **cp**: tipo de dolor de pecho.\n",
    "   - Valor 1: angina típica.\n",
    "   - Valor 2: angina atípica.\n",
    "   - Valor 3: dolor no anginoso.\n",
    "   - Valor 4: asintomático.\n",
    "4. **trestbps**: presión arterial en reposo (en mm Hg al ingresar al hospital).\n",
    "5. **chol**: colesterol sérico en mg/dl.\n",
    "6. **fbs**: azúcar en sangre en ayunas > 120 mg/dl (1 = verdadero; 0 = falso).\n",
    "7. **restecg**: resultados electrocardiográficos en reposo.\n",
    "   - Valor 0: normal.\n",
    "   - Valor 1: con anormalidad de onda ST-T (inversiones de onda T y/o elevación o depresión del ST de > 0.05 mV).\n",
    "   - Valor 2: muestra probable o definitiva hipertrofia ventricular izquierda según los criterios de Estes.\n",
    "8. **thalach**: frecuencia cardíaca máxima alcanzada.\n",
    "9. **exang**: angina inducida por el ejercicio (1 = sí; 0 = no).\n",
    "10. **oldpeak**: depresión del segmento ST inducida por el ejercicio en relación al reposo.\n",
    "11. **slope**: la pendiente del segmento ST durante el pico del ejercicio.\n",
    "    - Valor 1: ascendente.\n",
    "    - Valor 2: plano.\n",
    "    - Valor 3: descendente.\n",
    "12. **ca**: número de vasos principales (0-3) coloreados por fluoroscopia.\n",
    "13. **thal**: 3 = normal; 6 = defecto fijo; 7 = defecto reversible.\n",
    "14. **target**: variable objetivo, se refiere a la presencia de enfermedad cardíaca en el paciente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La edad media es de 54 años, los adultos tienen más probabilidades que los jóvenes de sufrir enfermedades cardiovasculares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a echarle un ojo al target\n",
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El target está balanceado y el dataset un poco sucio :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and train split\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a ver distribuciones\n",
    "train_set.hist(bins=50, figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature have different scale, it's a good idea to perform standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creeamos un pipeline para hacer un one hot encoding de las variables categoricas y además, hacemos un median target encoding para los valores nulos.\n",
    "# finalmente estandarizamos las escalas de las columnas\n",
    "cat_attr = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\"]\n",
    "num_attr = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\", \"ca\", \"thal\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attr),\n",
    "    (\"cat\", OneHotEncoder(), cat_attr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set.drop(\"target\", axis=1)\n",
    "y_train = train_set.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pr = full_pipeline.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo y evaluacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar con un simple clasificador binario como base, en este caso un Clasificador estocástico por descenso de gradiente (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo normal es hacer validación cruzada asique lo hacemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(sgd_clf, x_train_pr, y_train, cv=3, scoring=\"accuracy\")\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a pintar una matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es como hacer validacion cruzada pero retornando las predicciones\n",
    "preds = cross_val_predict(sgd_clf, x_train_pr, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora podemos pintar la matriz de confusion\n",
    "cm = confusion_matrix(y_train, preds)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver precision, recall y f1 socre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: \", precision_score(y_train, preds))\n",
    "print(\"Recall: \", recall_score(y_train, preds))\n",
    "print(\"F1 score: \", f1_score(y_train, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra metrica top es el roc auc score\n",
    "print(\"roc auc score:\", roc_auc_score(y_train, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo que ya es hora que usemos un modelo mas potente como el RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_preds = cross_val_predict(rf_clf, x_train_pr, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, rf_preds)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pintamos metricas\n",
    "print(\"Precision: \", precision_score(y_train, rf_preds))\n",
    "print(\"Recall: \", recall_score(y_train, rf_preds))\n",
    "print(\"F1 score: \", f1_score(y_train, rf_preds))\n",
    "print(\"roc auc score:\", roc_auc_score(y_train, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un poco mejor que el modelo base, vamos a usar el dataset entero para entrenar el RF Classifier y vemos que tal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(x_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_set.drop(\"target\", axis=1)\n",
    "y_test = test_set.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pr = full_pipeline.transform(x_test)\n",
    "final_preds = forest_clf.predict(x_test_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final metrics\n",
    "print(\"Precision: \", precision_score(y_test, final_preds))\n",
    "print(\"Recall: \", recall_score(y_test, final_preds))\n",
    "print(\"F1 score: \", f1_score(y_test, final_preds))\n",
    "print(\"roc auc score:\", roc_auc_score(y_test, final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fue un ejemplo sencillo de cómo evaluar un clasificador, ¡sin embargo, el resultado es bueno! La validación cruzada es un buen método para evaluar modelos, pero como dividimos nuestro conjunto de datos en 3 partes, el modelo tuvo pocos datos para lograr buenos resultados. ¡Con el conjunto de datos completo alcanzamos un buen resultado!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
